{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rea-time Face Landmark Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rqsGAHiVx-n"
      },
      "source": [
        "# Rea-time Face Landmark Detection with TensorflowJS React\n",
        "\n",
        "1 - Install dependencies  \n",
        "2 - Import dependencies  \n",
        "3 - Setup webcam and canvas  \n",
        "4 - Define references to those  \n",
        "5 - Load facemesh  \n",
        "6 - Detect function  \n",
        "7 - Drawing utilities  \n",
        "8 - Load triangulation  \n",
        "9 - Setup triangle path  \n",
        "10 - Setup point drawing  \n",
        "11 - Add drawMesh to detect function  \n",
        "\n",
        "<br>\n",
        "\n",
        "**References**  \n",
        "- Source code from:  \n",
        "  Nicholas Renotte (2020) Real Time AI Face Landmark Detection in 20 Minutes with Tensorflow.JS and React \n",
        "  https://www.youtube.com/watch?v=7lXYGDVHUNw&ab_channel=NicholasRenotte"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GontBz12BR1Y"
      },
      "source": [
        "## 1 - Install dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Azi0M9pDNPK"
      },
      "source": [
        "npm install @tensorflow.tfjs @tensorflow-models/facemesh react-webcam\n",
        "npm start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty-QwvcHB0wR"
      },
      "source": [
        "## 2 - Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qysEoFN7CHJm"
      },
      "source": [
        "import React, {useRef} from 'react';\n",
        "import * as tf from \"@tensorflow/tfjs\";\n",
        "import * as facemesh from \"@tensorflow-models/facemesh\";\n",
        "import Webcam from \"react-webcam\";\n",
        "import './App.css';"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkWVb-3UCHcJ"
      },
      "source": [
        "## 3 - Setup webcam and canvas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygoQtVgRCJ25"
      },
      "source": [
        "## 4 - Define references to those"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ogoRSaXaEssz",
        "outputId": "32d70d61-373b-4b87-fdd4-275512bbcbbe"
      },
      "source": [
        "Javascript(\"\"\"\n",
        "\n",
        "function App() {\n",
        "\n",
        "  // Setup references\n",
        "  const webcamRef = useRef(null);\n",
        "  const canvasRef = useRef(null);\n",
        "\n",
        "  // Set up webcam and canvas\n",
        "  return (\n",
        "    <div className='App'>  \n",
        "      <header className='App-header'>\n",
        "        <Webcam \n",
        "          ref={webcamRef}\n",
        "          style={{\n",
        "            position:\"absolute\",\n",
        "            marginLeft:'auto',\n",
        "            marginRight:'auto',\n",
        "            left:0,\n",
        "            right:0,\n",
        "            textAlign:'center',\n",
        "            zIndex:9,\n",
        "            width:800,\n",
        "            height:600\n",
        "          }}/>\n",
        "\n",
        "        <canvas\n",
        "          ref={canvasRef}\n",
        "          style={{\n",
        "            position:\"absolute\",\n",
        "            marginLeft:'auto',\n",
        "            marginRight:'auto',\n",
        "            left:0,\n",
        "            right:0,\n",
        "            textAlign:'center',\n",
        "            zIndex:9,\n",
        "            width:800,\n",
        "            height:600\n",
        "        }}/>\n",
        "      </header>\n",
        "    </div>\n",
        "  );\n",
        "}\n",
        "\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/javascript": [
              "\n",
              "\n",
              "import React, {useRef} from 'react';\n",
              "import * as tf from \"@tensorflow/tfjs\";\n",
              "import * as facemesh from \"@tensorflow-models/facemesh\";\n",
              "import Webcam from \"react-webcam\";\n",
              "import './App.css';\n",
              "\n",
              "function App() {\n",
              "\n",
              "  // Setup references\n",
              "  const webcamRef = useRef(null);\n",
              "  const canvasRef = useRef(null);\n",
              "\n",
              "  // Set up webcam and canvas\n",
              "  return (\n",
              "    <div className='App'>  \n",
              "      <header className='App-header'>\n",
              "        <Webcam \n",
              "          ref={webcamRef}\n",
              "          style={{\n",
              "            position:\"absolute\",\n",
              "            marginLeft:'auto',\n",
              "            marginRight:'auto',\n",
              "            left:0,\n",
              "            right:0,\n",
              "            textAlign:'center',\n",
              "            zIndex:9,\n",
              "            width:800,\n",
              "            height:600\n",
              "          }}/>\n",
              "\n",
              "        <canvas\n",
              "          ref={canvasRef}\n",
              "          style={{\n",
              "            position:\"absolute\",\n",
              "            marginLeft:'auto',\n",
              "            marginRight:'auto',\n",
              "            left:0,\n",
              "            right:0,\n",
              "            textAlign:'center',\n",
              "            zIndex:9,\n",
              "            width:800,\n",
              "            height:600\n",
              "        }}/>\n",
              "      </header>\n",
              "    </div>\n",
              "  );\n",
              "}\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLwVMuujIHYG"
      },
      "source": [
        "## 5 - Load facemesh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JelnhWbIFvq"
      },
      "source": [
        "Javascript(\"\"\"\n",
        "function App() {\n",
        "    ...\n",
        "  // Load facemesh\n",
        "  const runFacemesh = async () => {\n",
        "    const net = await facemesh.load({\n",
        "      inputResolution:{width:800, height:600}, scale:0.8\n",
        "    })\n",
        "  }\n",
        "\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frkHgw6QJcw4"
      },
      "source": [
        "## 6 - Detect function\n",
        "Key functions\n",
        "- `facemesh_model.estimateFaces(video)`;\n",
        "\n",
        "<br>\n",
        "\n",
        "- Get video properties\n",
        "- Set video width\n",
        "- Set canvas width\n",
        "- Make detections\n",
        "- Get canvas context for drawing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vUR6ao7Lch4"
      },
      "source": [
        "Javascript(\"\"\"\n",
        "\n",
        "  // Detect function\n",
        "  const detect = async (net) => {\n",
        "    if (typeof webcamRef.current !==\"undefined\" &&\n",
        "        webcamRef.current !== null &&\n",
        "        webcamRef.current.video.readyState == 4) {\n",
        "          // Get video properties\n",
        "          const video = webcamRef.current.video;\n",
        "          const videoWidth = webcamRef.current.video.videoWidth;\n",
        "          const videoHeight = webcamRef.current.video.videoHeight;\n",
        "\n",
        "          // Set vidieo width\n",
        "          webcamRef.current.video.width = videoWidth;\n",
        "          webcamRef.current.video.header = videoHeight;\n",
        "          \n",
        "          // Set canvas width\n",
        "          canvasRef.current.width = videoWidth;\n",
        "          canvasRef.current.header = videoHeight;\n",
        "\n",
        "          // Make detections\n",
        "          const face = await net.estimateFaces(video);\n",
        "          console.log(face);\n",
        "          \n",
        "          // Get canvas context for drawing\n",
        "\n",
        "        }\n",
        "  }\n",
        "\n",
        "  runFacemesh();\n",
        "\n",
        "  ...\n",
        "\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUDO-6HOCL2o"
      },
      "source": [
        "## 7 - Drawing utilities\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3tgm_ctPJFJ"
      },
      "source": [
        "## 8 - Load triangulation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKwsAluf01o7"
      },
      "source": [
        "## 9 - Setup triangle path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGJty7oj01tN"
      },
      "source": [
        "## 10 - Setup point drawing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JBgxn7_vcUZ"
      },
      "source": [
        "Javascript(\"\"\"\n",
        "export const TRIANGULATION = [ ... ]\n",
        "\n",
        "    // Draw the points\n",
        "    export const drawMesh = (predictions, ctx) => {\n",
        "        if (predictions.length > 0) {        // if prediction data is available,\n",
        "            \n",
        "            predictions.forEach((prediction) => {  \n",
        "                const keypoints = prediction.scaledMesh;      // get scaled mesh keys \n",
        "            \n",
        "            // Draw triangles\n",
        "            for (let i=0; i<TRIANGULATION.length/3; i++){\n",
        "                const points = [\n",
        "                    TRIANGULATION[i * 3],\n",
        "                    TRIANGULATION[i * 3 + 1],\n",
        "                    TRIANGULATION[i * 3 + 2],\n",
        "                ].map((index) => keypoints[index]);\n",
        "                drawPath(ctx, points, true);\n",
        "            }\n",
        "        \n",
        "            for (let i = 0; i < keypoints.length; i++) {  // loop through\n",
        "                const x = keypoints[i][0];                // each keypoint\n",
        "                const y = keypoints[i][1];\n",
        "                ctx.beginPath();\n",
        "                ctx.arc(x, y, 1, 0, 3 * Math.PI);\n",
        "                ctx.fillStyle = 'aqua';\n",
        "                ctx.fill(); \n",
        "            }\n",
        "        });\n",
        "    }\n",
        "};\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEB4AP6c01yw"
      },
      "source": [
        "## 11 - Add drawMesh to detect function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RivW47nc1FlD"
      },
      "source": [
        "Javascript(\"\"\"\n",
        "\n",
        "  // Detect function\n",
        "  const detect = async (net) => {\n",
        "    if (typeof webcamRef.current !== \"undefined\" &&\n",
        "        webcamRef.current !== null &&\n",
        "        webcamRef.current.video.readyState === 4) {\n",
        "          // Get video properties\n",
        "          const video = webcamRef.current.video;\n",
        "          const videoWidth = webcamRef.current.video.videoWidth;\n",
        "          const videoHeight = webcamRef.current.video.videoHeight;\n",
        "\n",
        "          // Set vidieo width\n",
        "          webcamRef.current.video.width = videoWidth;\n",
        "          webcamRef.current.video.height = videoHeight;\n",
        "          \n",
        "          // Set canvas width\n",
        "          canvasRef.current.width = videoWidth;\n",
        "          canvasRef.current.height = videoHeight;\n",
        "\n",
        "          // Make detections\n",
        "          const face = await net.estimateFaces(video);\n",
        "          console.log(face);\n",
        "          \n",
        "          // Get canvas context for drawing\n",
        "          const ctx = canvasRef.current.getContext(\"2d\");\n",
        "          drawMesh(face, ctx);                              // add mesh\n",
        "        }\n",
        "  }\n",
        "\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
